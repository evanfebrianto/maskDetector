{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a306054-3c97-41f4-895b-8d244e0c976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef5a0a6-e733-4d29-a63b-527ea921121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "PADDING = 25\n",
    "\n",
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c6c532-50f1-48ed-8648-430cb807b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "        transforms.Resize(size=(64,64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "class_names = ['incorrect_mask', 'mask', 'no_mask']\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbf5b26-9126-4634-9d31-17f83650367b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = models.resnet18(pretrained=True)  \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))  # make the change\n",
    "model.load_state_dict(torch.load('models/model_ft.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0f94b3-5d22-4be1-b1f4-cb6a1c439356",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3907162045.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_73336/3907162045.py\"\u001b[0;36m, line \u001b[0;32m62\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=5,\n",
    "    min_detection_confidence=0.3,\n",
    "    min_tracking_confidence=0.2) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    original_frame_rgb = image.copy()\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "        for i, face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "#             mp_drawing.draw_landmarks(\n",
    "#                 image=image,\n",
    "#                 landmark_list=face_landmarks,\n",
    "#                 connections=mp_face_mesh.FACE_CONNECTIONS,\n",
    "#                 landmark_drawing_spec=drawing_spec,\n",
    "#                 connection_drawing_spec=drawing_spec)\n",
    "\n",
    "            h, w, c = image.shape\n",
    "            cx_min=  w\n",
    "            cy_min = h\n",
    "            cx_max= cy_max= 0\n",
    "            for id, lm in enumerate(face_landmarks.landmark):\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                if cx<cx_min:\n",
    "                    cx_min=cx\n",
    "                if cy<cy_min:\n",
    "                    cy_min=cy\n",
    "                if cx>cx_max:\n",
    "                    cx_max=cx\n",
    "                if cy>cy_max:\n",
    "                    cy_max=cy\n",
    "            cx_min -= PADDING\n",
    "            cy_min -= PADDING\n",
    "            cx_max += PADDING\n",
    "            cy_max += PADDING\n",
    "            \n",
    "            # Classify\n",
    "            try:\n",
    "                crop_img = original_frame_rgb[cy_min:cy_max, cx_min:cx_max]\n",
    "                im_pil = Image.fromarray(crop_img)\n",
    "                with torch.no_grad():\n",
    "                    img = transformer(im_pil).unsqueeze(0)\n",
    "                    inputs = img.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    label = class_names[preds]  \n",
    "            except ValueError:\n",
    "                continue\n",
    "            \n",
    "            # Visualize\n",
    "            if label == 'no_mask':\n",
    "                cv2.rectangle(image, (cx_min, cy_min), (cx_max, cy_max), (0, 0, 255), 2)\n",
    "            elif label == 'incorrect_mask':\n",
    "                cv2.rectangle(image, (cx_min, cy_min), (cx_max, cy_max), (0, 240, 255), 2)\n",
    "            else: # label == mask\n",
    "                cv2.rectangle(image, (cx_min, cy_min), (cx_max, cy_max), (0, 255, 0), 2)\n",
    "            cv2.imshow('Faces-'+str(i), crop_img)\n",
    "    cv2.imshow('Frame', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac5117-b25d-4bde-8e1f-0f0fd0bf958c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
